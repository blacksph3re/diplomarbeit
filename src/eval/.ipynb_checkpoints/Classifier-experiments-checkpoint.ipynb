{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8742332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pyts.image import GramianAngularField\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tqdm.notebook as tqdm\n",
    "import itertools\n",
    "import lzma\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65287bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKAHEAD_LEN = 50\n",
    "LOOKBACK_LEN = 224\n",
    "CLASSES = [0, 0.8, 0.95, 0.99]\n",
    "CE_WEIGHTS = [1, 1, 1, 2] # Slightly higher weights for higher loads trade more false positives for less false negatives\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "DATA_DIRECTORY = '../../results/baselines/turbulent_sweep_ipc'\n",
    "END_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb72be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(files):\n",
    "    tmplist = []\n",
    "    for file in tqdm.tqdm(files, desc=\"Preprocessing\"):\n",
    "        with lzma.open(file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "#         x = data['episodes']\n",
    "#         x = garage.np.pad_batch_array(x.env_infos['orig_state'], x.lengths, max(x.lengths))\n",
    "#         tmplist.append(x[:,:,[7,8,9]]) # Extract oop blade bendings\n",
    "        x = np.array(data['states'])\n",
    "        tmplist.append(x[:,:,[7,8,9]])\n",
    "    return np.concatenate(tmplist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0c76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WindturbineDataset(\n",
    "torch.utils.data.Dataset):\n",
    "    def __init__(self, data, statistics):\n",
    "        super(WindturbineDataset).__init__()\n",
    "        self.data = data\n",
    "        self.mean = statistics['mean']\n",
    "        self.std = statistics['std']\n",
    "        self.transformer = GramianAngularField(image_size=LOOKBACK_LEN, sample_range=None)\n",
    "        self.views = [[0,1,2], [1,2,0], [2,0,1]]\n",
    "        self.quantiles = statistics['quantiles']\n",
    "    \n",
    "    def index_transform(self, i):\n",
    "        i = int(i)\n",
    "        bladeview = i % 3\n",
    "        i = int(np.floor(i/3))\n",
    "        run = int(np.floor(i / (self.data.shape[1] - LOOKAHEAD_LEN-LOOKBACK_LEN)))\n",
    "        idx = int(i - run * (self.data.shape[1] - LOOKAHEAD_LEN - LOOKBACK_LEN) + LOOKBACK_LEN)\n",
    "        return run, idx, bladeview\n",
    "    \n",
    "    def calc_label(self, run, idx, bladeview):\n",
    "        snippet = self.data[run, idx:(idx+LOOKAHEAD_LEN), bladeview]\n",
    "        m = np.max(snippet[10:])\n",
    "        for i in [i-1 for i in range(len(CLASSES), 0, -1)]:\n",
    "            if m >= self.quantiles[i]:\n",
    "                return i\n",
    "        return 0\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return [self.calc_label(run, idx, blade) for (run, idx, blade) in (self.index_transform(i) for i in range(len(self)))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]*(self.data.shape[1]-LOOKAHEAD_LEN-LOOKBACK_LEN) * 3\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        run, idx, bladeview = self.index_transform(i)\n",
    "        tmp_data = np.clip((self.data[run, (idx-LOOKBACK_LEN):idx, :] - self.mean) / (2*self.std), -1, 1)\n",
    "        tmp_data = self.transformer.transform(tmp_data.transpose())\n",
    "        tmp_data = torch.tensor(tmp_data[self.views[bladeview],:,:], dtype=torch.float32)\n",
    "        label = self.calc_label(run, idx, bladeview)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return tmp_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b066354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_new_training():\n",
    "    # Prepare datasets\n",
    "    files = [os.path.join(DATA_DIRECTORY, f) for f in os.listdir(DATA_DIRECTORY)]\n",
    "    ds = preprocess(files)\n",
    "    statistics = {\n",
    "        'mean': np.mean(ds),\n",
    "        'std': np.std(ds),\n",
    "        'quantiles': [np.quantile(ds, q) for q in CLASSES],\n",
    "    }\n",
    "\n",
    "    train_indices = np.random.choice(range(ds.shape[0]), int(ds.shape[0]*0.85), False)\n",
    "    test_indices = [i for i in range(ds.shape[0]) if i not in train_indices]\n",
    "    ds_train = WindturbineDataset(ds[train_indices], statistics)\n",
    "    ds_test = WindturbineDataset(ds[test_indices], statistics)\n",
    "\n",
    "    # Save test indices for saving/loading\n",
    "    statistics['test_indices'] = test_indices\n",
    "    \n",
    "    model = torch.hub.load('pytorch/vision:v0.8.0', 'resnet18', pretrained=True)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, len(CLASSES))\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    return ds_train, ds_test, statistics, model, optim, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_state(checkpoint_path):\n",
    "    files = [os.path.join(DATA_DIRECTORY, f) for f in os.listdir(DATA_DIRECTORY)]\n",
    "    ds = preprocess(files)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    print('Loaded training state from %s, starting at epoch %d' % (checkpoint_path, checkpoint['epoch']))\n",
    "    statistics = checkpoint['statistics']\n",
    "    test_indices = checkpoint['test_indices']\n",
    "    train_indices = [i for i in range(ds.shape[0]) if i not in test_indices]\n",
    "    \n",
    "    ds_train = WindturbineDataset(ds[train_indices], statistics)\n",
    "    ds_test = WindturbineDataset(ds[test_indices], statistics)\n",
    "    \n",
    "    return ds_train, ds_test, statistics, checkpoint['model'], checkpoint['optim'], checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0fe38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3845845aba4e4d818c192ff5aa51ae60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sph3re/.cache/torch/hub/pytorch_vision_v0.8.0\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_test, statistics, model, optim, start_epoch = start_new_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e65da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_datapoints(labels):\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    return 1.0 / counts[labels] # Weight samples inverse to their occurrence so the network sees every class with the same frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730149ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_weights = weight_datapoints(ds_train.get_labels())\n",
    "dl_train = torch.utils.data.DataLoader(ds_train,\n",
    "                                       sampler=torch.utils.data.WeightedRandomSampler(train_weights,\n",
    "                                                                                      num_samples=len(ds_train),\n",
    "                                                                                      replacement=True),\n",
    "                                       batch_size=64,\n",
    "                                       num_workers=4,\n",
    "                                       prefetch_factor=int(64/4),\n",
    "                                       pin_memory=False)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test,\n",
    "                                      batch_size=512,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=4,\n",
    "                                      pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942ec290",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c854d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 13:46:08.525148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/sph3re/.mujoco/mujoco200/bin\n",
      "2021-12-03 13:46:08.525168: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(CE_WEIGHTS, dtype=torch.float32))\n",
    "log = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "354acde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, criterion, device, dataloader, calc_grads=True):\n",
    "    run_name = ''\n",
    "    if calc_grads:\n",
    "        model.train()\n",
    "        run_name = 'Train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        run_name = 'Eval'\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    running_confusion = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.int64)\n",
    "    size = 0\n",
    "    \n",
    "    for feat, label in tqdm.tqdm(dataloader, desc=run_name):\n",
    "        confusion = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.int64)\n",
    "        feat = feat.to(device)\n",
    "        label = label.to(device)\n",
    "        if calc_grads:\n",
    "            optim.zero_grad()\n",
    "            outputs = model(feat)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(feat)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, label)\n",
    "\n",
    "        size += feat.size(0)\n",
    "        running_loss += loss.item() * feat.size(0)\n",
    "        running_corrects += torch.sum(preds == label.data)\n",
    "        for p, l in zip(preds, label):\n",
    "            confusion[p,l] += 1\n",
    "        running_confusion += confusion\n",
    "        acc = torch.sum(preds == label.data) / feat.size(0)\n",
    "#         tqdm.tqdm.write('{:.4f} {:.4f}'.format(loss.item(), acc))\n",
    "#         tqdm.tqdm.write('{}'.format(confusion))\n",
    "\n",
    "        if size > 1000:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    epoch_loss = running_loss / size\n",
    "    epoch_acc = running_corrects.double() / size\n",
    "\n",
    "#     tqdm.tqdm.write('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "#     tqdm.tqdm.write('{}'.format(running_confusion))\n",
    "    \n",
    "    return epoch_loss, epoch_acc, running_confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8cffdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    cm = cm.transpose()\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "#     cm = np.around(cm / cm.sum(axis=0)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97806538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2835d295651423dbb14693aab380815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dec8711213341f78d4d45116e7991d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/27994 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sph3re/.anaconda3/envs/rl/lib/python3.9/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.tqdm(range(start_epoch, END_EPOCH), desc='Epoch'):\n",
    "    loss, acc, cm = train(model, optim, criterion, device, dl_train, True)\n",
    "    log.add_scalar('loss/train', loss, epoch)\n",
    "    log.add_scalar('acc/train', acc, epoch)\n",
    "    fig = plot_confusion_matrix(cm.numpy(), CLASSES)\n",
    "    log.add_figure('confusion/train', fig, epoch, close=True)\n",
    "    \n",
    "    loss, acc, cm = train(model, optim, criterion, device, dl_test, False)\n",
    "    fig = plot_confusion_matrix(cm.numpy(), CLASSES)\n",
    "    log.add_scalar('loss/eval', loss, epoch)\n",
    "    log.add_scalar('acc/eval', acc, epoch)\n",
    "    log.add_figure('confusion/eval', fig, epoch, close=True)\n",
    "    log.flush()\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'optimizer': optim,\n",
    "        'statistics': statistics\n",
    "    }, 'runs/checkpoint-%d.pth' % epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f5967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('rl': conda)",
   "language": "python",
   "name": "python39564bitrlcondaddc46d847c76465e93cf0995bad56a9d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
